## 1. 해야할 것 과 오늘 한 것

- **object detection 모델 분석하기  30%**
- get points 분석하기 100%
- object detection 의 입력형과 get points  입력형 맞추기  0%
    - *이것만 해결하면 제대로된 결과를 낼 수 있음. 하지만 이 부분이 어려움
- GAN 모델 오류 해결(shape error)  80%
    - 감정 분류 -> GAN 학습 shape 맞추기 0%
- **gan 모델 성능 평가하기 0% (안 건드림)**
- **object detection 모델 성능 평가하기 0% (안 건드림)**
    - **object detection은 IoU를 사용하기 Area of Overlap / Area of Union**

## 2. 진행 상황 :

mask_image(x_batch) 함수를 get_points() 함수로 형으로 바꿔야한다.
get_points()의 return 은

```python
return np.array(points), np.array(mask)

```

이고

이것의 형이

```python
np.array(points.shape) :(16, 4), np.array(mask).shape :(16, 128, 128, 1)

```

이다.

```python
points_batch, mask_batch = get_points()

```

위를 에서 받아서

```python
_, g_loss, completion = sess.run([g_train_op, model.g_loss, model.completion], feed_dict={x: x_batch, mask: mask_batch, is_training: True})

```

위 함수의 입력값으로 넣어줘야 한다.

당장 해야할 것이 get_points 함수를 뜯어보는 것이다.

get_points 함수는

```python
    while True:
        if sess.run(epoch) <= PRETRAIN_EPOCH:
            for i in tqdm.tqdm(range(step_num)):
                x_batch = x_train[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]
                points_batch, mask_batch = get_points()

```

위에서 while문 안의 step_num만큼 도는데 step_num은 x_train의 개수를 batch_size로 나눈 것이다.
여기서 batch_size는 16이다.

```python
step_num = int(len(x_train) / BATCH_SIZE)

```

```python
 def get_points():
    points = []
    mask = []
    for _ in range(BATCH_SIZE):
        x1, y1 = np.random.randint(0, IMAGE_SIZE - LOCAL_SIZE + 1, 2)
        x2, y2 = np.array([x1, y1]) + LOCAL_SIZE

        points.append([x1, y1, x2, y2])

        w, h = np.random.randint(HOLE_MIN, HOLE_MAX + 1, 2)
        p1 = x1 + np.random.randint(0, LOCAL_SIZE - w)
        q1 = y1 + np.random.randint(0, LOCAL_SIZE - h)
        p2 = p1 + w
        q2 = q1 + h

        m = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 1), dtype=np.uint8)
        m[q1:q2 + 1, p1:p2 + 1] = 1
        mask.append(m)
        print()
    print("#################")
    #print(f"np.array(points) :{np.array(points)}, np.array(mask) :{np.array(mask)} ")
    print(f"np.array(points.shape) :{np.array(points).shape}, np.array(mask).shape :{np.array(mask).shape} ")
    return np.array(points), np.array(mask)

```

## 3. 더 해야할 것 :

## 1. 해야할 것

**gan 모델 성능 평가하기**

**object detection 모델 성능 평가하기**

**object detection은 IoU를 사용하기 Area of Overlap / Area of Union**

## 2. 진행 상황 :

mask_image(x_batch) 함수를 get_points() 함수로 형으로 바꿔야한다.
get_points()의 return 은

```python
return np.array(points), np.array(mask)

```

이고

이것의 형이

```python
np.array(points.shape) :(16, 4), np.array(mask).shape :(16, 128, 128, 1)

```

이다.

```python
points_batch, mask_batch = get_points()

```

위를 에서 받아서

```python
_, g_loss, completion = sess.run([g_train_op, model.g_loss, model.completion], feed_dict={x: x_batch, mask: mask_batch, is_training: True})

```

위 함수의 입력값으로 넣어줘야 한다.

당장 해야할 것이 get_points 함수를 뜯어보는 것이다.

```python
step_num = int(len(x_train) / BATCH_SIZE)

```

get_points 함수는

```python
    while True:
        if sess.run(epoch) <= PRETRAIN_EPOCH:
            for i in tqdm.tqdm(range(step_num)):
                x_batch = x_train[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]
                points_batch, mask_batch = get_points()
```

위에서 while문 안의 step_num만큼 도는데 <strong>step_num</strong>은 x_train의 개수를 batch_size로 나눈 것이다.
여기서 batch_size는 16이다.

```python
 def get_points():
    points = []
    mask = []
    for _ in range(BATCH_SIZE):
        x1, y1 = np.random.randint(0, IMAGE_SIZE - LOCAL_SIZE + 1, 2)
        x2, y2 = np.array([x1, y1]) + LOCAL_SIZE

        points.append([x1, y1, x2, y2])

        w, h = np.random.randint(HOLE_MIN, HOLE_MAX + 1, 2)
        p1 = x1 + np.random.randint(0, LOCAL_SIZE - w)
        q1 = y1 + np.random.randint(0, LOCAL_SIZE - h)
        p2 = p1 + w
        q2 = q1 + h

        m = np.zeros((IMAGE_SIZE, IMAGE_SIZE, 1), dtype=np.uint8)
        m[q1:q2 + 1, p1:p2 + 1] = 1
        mask.append(m)
        print()
    print("#################")
    #print(f"np.array(points) :{np.array(points)}, np.array(mask) :{np.array(mask)} ")
    print(f"np.array(points.shape) :{np.array(points).shape}, np.array(mask).shape :{np.array(mask).shape} ")
    return np.array(points), np.array(mask)

```

get_points를 뜯어보면 points를 저장하는 배열과 mask를 저장하는 배열이 선언되고 points에 [x1,y1,x2,y2]가 16번 저장되는데, 실제로 아래와 같이 저장된다. 이게 랜덤으로 생성되는네모 상자를 좌표를 뜻한다. 위 x1, y1, x2, y2를 mask objection으로 찾은 영역으로 대체해줘야 한다. 

한가지 문제인 것은 이미지를 받아오는 것이다.

```python
points_batch : [[  5  62  69 126]
 [ 54   4 118  68]
 [ 15  45  79 109]
 [ 13  45  77 109]
 [ 59  43 123 107]
 [ 26  64  90 128]
 [ 40  49 104 113]
 [  5  29  69  93]
 [ 47  45 111 109]
 [  3  45  67 109]
 [ 15  40  79 104]
 [ 34  27  98  91]
 [ 11  37  75 101]
 [ 35   3  99  67]
 [ 11  48  75 112]
 [ 50  25 114  89]], mask_batch : [[[[0]
```

gan 모델의 크기는 128 * 128 사이즈 이므로 detection하는 것도 128 * 128로 통일해줘야 한다.

원래 gan 모델에서는 이미지 파일의 batch 파일로 만들어서 동작시지만 mask_image에서는 로컬에 있는 이미지 파일을 그대로 사용한다. mask_image의 이미지 파일을 to_num_2.py를 사용해서 numpy파일로 바꾸고 이 바꾼 내용을 사용할 수 있게 바꿔주는 동작이 필요하다. 그럼 train 파일의 도입부에서의 batch 파일을 어떻게 사용하는 지 분석해야 하고, 이를 토대로 mask_image 함수를 바꿔줘야 한다.

## 3. 추가된 해야할 것 :

1.  train 파일에서 batch 파일을 어떻게 사용하는 지 분석하기 0 % 
2. mask_image()에서 일반 image 말고 batch 파일을 받아서 사용하게 만들기 0 %
