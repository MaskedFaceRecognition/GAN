## 1. 해야할 것 과 오늘 한 것

- train 파일에서 batch 파일을 어떻게 사용하는 지 분석 완료하기 80 % → 100 %
- get_points(x_batch) 함수 수정 40% (에러 잡는 중)
- mask_image()에서 일반 image 말고 batch 파일을 받아서 사용하게 만들기 0 %

추가로 생각해야 할 것 :

- mask_image()에서는 이미지으로 그부분을

## 2. 진행 상황 :

저번한거

```python
x_batch.shape : (16, 128, 128, 3)
```

위와 같이 나온다.

그리고 학습 시키는 것을

```python
_, g_loss = sess.run([g_train_op, model.g_loss], feed_dict={x: x_batch, mask: mask_batch, is_training: True})
```

위에서 하는데,sess.run의 feed_dict에 사용하는 x : x_batch가 x에 x_batch를 넣은 값이라는 뜻이다. 앞에서 placeholder로 선언 한 것을 sess.run의 변수로 사용하기 위해 위 코드와 같이 사용한다.

그리고 돌아가지 않은 코드가

```python

            x_batch = x_test[:BATCH_SIZE]
            print(f'yes?')
            ###########
            ### 여기 다음이 돌아가지 않는다. feed dict를 설정해야 한다. x batch 자체가 이상한듯?
            #print(f'x :{x}, mask : {mask}')
            completion = sess.run(model.completion, feed_dict={x: x_batch, mask: mask_batch, is_training: False})
            ###########
```

### 위 부분인데 지금 보니 x_batch에 x_test를 저장하는데 이게 잘못되지 않았나 싶다어 바르게 수정해야 할 듯하다.

---

그러면 x_test의 형을 보자.

```python
x_test.shape : (95, 128, 128, 3)
```

x_test는 test 이미지 95개를 합친 것이다.

**여기서 우리가 해야할 것을 다시 생각하면 get_points와 mask_image를 합치는 것이다.**

**이제 mask_image 함수 분석하자.**

함수를 보면 

args에 딕셔너리 형태로 변수를 관리한다.

image에는 가져올 picture명을, face에는 face detector model로는 mask_detector.model을 사용하고 confidence는 0.5로 사용한다.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6a415372-c1d7-4fa7-a2fe-eac0b5638c06/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6a415372-c1d7-4fa7-a2fe-eac0b5638c06/Untitled.png)

os.path.sep.join 는 경로 분리자인데, 

face_detector에 있는 deploy.prototext를 보면

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f82bd1a4-5d66-4525-b7d4-e4353ea1772b/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f82bd1a4-5d66-4525-b7d4-e4353ea1772b/Untitled.png)

input shape 부터 시작해서  layer들이 json 형식으로 정해져 있다. 

prototxt 파일을 찾아보니 모델에 대한 정의, 파라미터를 포함하는 파일이라고 나와있었다.

caffemodel은 훈련된 모델이라고 나와있었다.

- prototxt와 caffemodel 참고 사이트

```python
net = cv2.dnn.readNet(prototxtPath, weightsPath)
```

위 두 개 파일로 readNet 모델을 learning 시킨다 

- **DNN 모듈로 딥러닝 시키기 참고 자료 *****

그리고 모델을 불러오고,

```python
model = load_model(args["model"])
```

image를 imread로 이미지를 읽어온다.

```python
image = cv2.imread(args["image"])
```

image를 받아오는 부분만 통일 일단 여기까지 해석하고 이 부분을 get_points()에서 배치 이미지를 가져와서 저장하는 부분을 바꿔보자 

먼저 get_points에서 기존 이미지를 받아와야 한다.

get_points에는 이미지를 받아오지 않는다.

그래서 get_points에 x_batch를 가져오고, mask_image에 합치고 에러 수정 중이다.

```python
File "train.py", line 197, in get_points
    (104.0, 177.0, 123.0))
cv2.error: OpenCV(4.5.1) C:\Users\appveyor\AppData\Local\Temp\1\pip-req-build-vijyisc5\opencv\modules\dnn\src\dnn.cpp:381: error: (-215:Assertion failed) image.depth() == blob_.depth() in function 'cv::dnn::dnn4_v20201117::blobFromImages
```

- mask_image 추가 분석
- 추가 dnn 프로세스 참고

    [https://m.blog.naver.com/tommybee/222067664722](https://m.blog.naver.com/tommybee/222067664722)
