import tensorflow as tf
import tensorflow.keras as K

def upscale_layer(layer, upscale_factor):
    '''
    upscale_factor(int)ë§Œí¼ ì¸µ(í…ì„œ)ì„ ì—…ìŠ¤ì¼€ì¼í•©ë‹ˆë‹¤.
    í…ì„œ í¬ê¸°ëŠ” [group, height, width, channels]ì…ë‹ˆë‹¤.
    '''
    height, width = layer.get_shape()[1:3]
    size = (upscale_factor * height, upscale_factor * width)
    upscaled_layer = tf.image.resize_nearest_neighbor(layer, size)
    return upscaled_layer

def smoothly_merge_last_layer(list_of_layers, alpha):
    '''
    ì„ê³—ê°’ ì•ŒíŒŒë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸µì„ ë¶€ë“œëŸ½ê²Œ í•©ì¹©ë‹ˆë‹¤.
    ì´ í•¨ìˆ˜ëŠ” ëª¨ë“  ì¸µì´ ì´ë¯¸ RGBë¡œ ë°”ë€Œì—ˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    ìƒì„±ìë¥¼ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    :list_of_layers    :   í•´ìƒë„(í¬ê¸°) ìˆœì„œëŒ€ë¡œ ì •ë ¬ëœ í…ì„œ ë¦¬ìŠ¤íŠ¸
    :alpha             :   (0,1) ì‚¬ì´ì˜ ì‹¤ìˆ˜
    '''
    # ì—…ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•´ ëì—ì„œ ë‘ ë²ˆì§¸ ì¸µì„ ì„ íƒí•©ë‹ˆë‹¤.
    last_fully_trained_layer = list_of_layers[-2]
    # ë§ˆì§€ë§‰ìœ¼ë¡œ í›ˆë ¨ëœ ì¸µì„ ì—…ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.
    last_layer_upscaled = upscale_layer(last_fully_trained_layer, 2)

    # ìƒˆë¡œ ì¶”ê°€ëœ ì¸µì€ ì•„ì§ ì™„ì „íˆ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
    larger_native_layer = list_of_layers[-1]

    # í•©ì¹˜ê¸° ì „ì— ì¸µ í¬ê¸°ê°€ ê°™ì€ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    assert larger_native_layer.get_shape() == last_layer_upscaled.get_shape()

    # ê³±ì…ˆì€ ë¸Œë¡œë“œìºìŠ¤íŒ…ë˜ì–´ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    new_layer = (1-alpha) * last_layer_upscaled + larger_native_layer * alpha

    return new_layer

def minibatch_std_layer(layer, group_size=4):
    '''
    ì¸µì˜ ë¯¸ë‹ˆë°°ì¹˜ í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì¸µì˜ ë°ì´í„° íƒ€ì…ì€ float32ë¡œ ê°€ì •í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ íƒ€ì… ë³€í™˜ì´ í•„ìš”í•©ë‹ˆë‹¤.
    '''
    # ë¯¸ë‹ˆë°°ì¹˜ëŠ” group_sizeë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆê±°ë‚˜ group_size ë³´ë‹¤ ê°™ê±°ë‚˜ ì‘ì•„ì•¼ í•©ë‹ˆë‹¤.
    group_size = K.backend.minimum(group_size, tf.shape(layer)[0])

    # ê°„ë‹¨í•˜ê²Œ ì“°ê¸° ìœ„í•´ í¬ê¸° ì •ë³´ë¥¼ ë”°ë¡œ ì €ì¥í•©ë‹ˆë‹¤. 
    # ê·¸ë˜í”„ ì‹¤í–‰ ì „ì—ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë°°ì¹˜ ì°¨ì›ì´ Noneì´ê¸° ë•Œë¬¸ì— tf.shapeì—ì„œ ì´ í¬ê¸°ë¥¼ ì–»ìŠµë‹ˆë‹¤.
    shape = list(K.int_shape(input))
    shape[0] = tf.shape(input)[0]

    # ë¯¸ë‹ˆë°°ì¹˜ ìˆ˜ì¤€ì—ì„œ ì—°ì‚°í•˜ê¸° ìœ„í•´ í¬ê¸°ë¥¼ ë°”ê¿‰ë‹ˆë‹¤. 
    # ì´ ì½”ë“œëŠ” ì¸µì´ [ê·¸ë£¹(G), ë¯¸ë‹ˆë°°ì¹˜(M), ë„ˆë¹„(W), ë†’ì´(H), ì±„ë„(C)]ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤. 
    # í•˜ì§€ë§Œ ì”¨ì•„ë…¸(Theano) ë°©ì‹ì˜ ìˆœì„œë¥¼ ì‚¬ìš©í•˜ëŠ” êµ¬í˜„ë„ ìˆìŠµë‹ˆë‹¤.
    minibatch = K.backend.reshape(layer, (group_size, -1, shape[1], shape[2], shape[3]))

    # [M, W, H, C] ê·¸ë£¹ì˜ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    minibatch -= tf.reduce_mean(minibatch, axis=0, keepdims=True)
    # [M, W, H, C] ê·¸ë£¹ì˜ ë¶„ì‚°ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    minibatch = tf.reduce_mean(K.backend.square(minibatch), axis = 0)
    # [M,W,H,C] ê·¸ë£¹ì˜ í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    minibatch = K.backend.square(minibatch + 1e-8)
    # íŠ¹ì„± ë§µì„ í‰ê· í•˜ì—¬ [M,1,1,1] í”½ì…€ì„ ì–»ìŠµë‹ˆë‹¤.
    minibatch = tf.reduce_mean(minibatch, axis=[1,2,3], keepdims=True)
    # ìŠ¤ì¹¼ë¼ ê°’ì„ ê·¸ë£¹ê³¼ í”½ì…€ì— ë§ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
    minibatch = K.backend.tile(minibatch, [group_size, 1, shape[2], shape[3]])
    # ìƒˆë¡œìš´ íŠ¹ì„± ë§µì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    return K.backend.concatenate([layer, minibatch], axis=1)

def equalize_learning_rate(shape, gain, fan_in=None):
    '''
    He ì´ˆê¸°í™”ì˜ ìƒìˆ˜ë¡œ ëª¨ë“  ì¸µì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ 
    íŠ¹ì„±ë§ˆë‹¤ ê°ê¸° ë‹¤ë¥¸ ë‹¤ì´ë‚˜ë¯¹ ë ˆì¸ì§€ë¥¼ ê°€ì§€ë„ë¡ ë¶„ì‚°ì„ ë§ì¶¥ë‹ˆë‹¤.
    shape   :   í…ì„œ(ì¸µ)ì˜ í¬ê¸°: ê° ì¸µì˜ ì°¨ì›ì…ë‹ˆë‹¤.
        ì˜ˆë¥¼ ë“¤ì–´, [4,4,48,3]. ì´ ê²½ìš° [ì»¤ë„í¬ê¸°, ì»¤ë„í¬ê¸°, í•„í„°ê°œìˆ˜, íŠ¹ì„±ë§µ]ì…ë‹ˆë‹¤. 
        í•˜ì§€ë§Œ êµ¬í˜„ì— ë”°ë¼ ì¡°ê¸ˆ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    gain    :   ì¼ë°˜ì ìœ¼ë¡œ sqrt(2)
    fan_in  :   ì„¸ì´ë¹„ì–´/He ì´ˆê¸°í™”ì—ì„œ ì…ë ¥ ì—°ê²° ê°œìˆ˜
    '''

    # ê¸°ë³¸ê°’ì€ íŠ¹ì„± ë§µ ì°¨ì›ì„ ì œì™¸í•˜ê³  shapeì˜ ëª¨ë“  ì°¨ì›ì„ ê³±í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‰´ëŸ°ë§ˆë‹¤ ì…ë ¥ ì—°ê²° ê°œìˆ˜ë¥¼ ì–»ìŠµë‹ˆë‹¤.
    if fan_in is None: fan_in = np.prod(shape[:-1])
    # He ì´ˆê¸°í™” ìƒìˆ˜ (He et al, 2015)
    std = gain / K.sqrt(fan_in)
    # ì¡°ì •ì„ ìœ„í•œ ìƒìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    wscale = K.constant(std, name='wscale', dtype=np.float32)
    # ê°€ì¤‘ì¹˜ ê°’ì„ ì–»ì–´ ë¸Œë¡œë“œìºìŠ¤íŒ…ìœ¼ë¡œ wscaleì„ ì ìš©í•©ë‹ˆë‹¤.
    adjusted_weights = K.get_value('layer', shape=shape, 
            initializer=tf.initializers.random_normal()) * wscale
    return adjusted_weights

def pixelwise_feat_norm(inputs, **kwargs):
    '''
    Krizhevsky ë“±ì´ 2012ë…„ ë…¼ë¬¸ì— ì œì•ˆí•œ í”½ì…€ë³„ íŠ¹ì„± ì •ê·œí™”
    :inputs : ì¼€ë¼ìŠ¤ / TF ì¸µ
    '''
    normalization_constant = K.backend.sqrt(K.backend.mean(
                    inputs**2, axis=-1, keepdims=True) + 1.0e-8)
    return inputs / normalization_constant


